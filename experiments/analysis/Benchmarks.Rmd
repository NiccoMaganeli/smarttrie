---
title: "SmartTrie - Project Benchmarks"
output:
  pdf_document: 
    fig_crop: no
    fig_height: 4
    fig_width: 7
    toc: yes
  html_notebook:
    code_folding: none
    toc: yes
---

```{r predef, warning=FALSE, include=FALSE}
library(stringr)
library(dplyr)
library(ggplot2)
library(scales)

load_ycsb_througput = function(log_file_path) {
  ycsb_lines = regex(
    paste(
      "(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}:\\d{3}).*",
      "\\[UPDATE:",
      "Count=(.*),",
      "Max=(.*),",
      "Min=(.*),",
      "Avg=(.*),",
      "90=(.*),",
      "99=(.*),",
      "99.9=(.*),",
      "99.99=(.*)]"
    )
  )

  ycsb = str_match(readLines(log_file_path), ycsb_lines)
  ycsb = ycsb[!is.na(ycsb[, 1]),]
  ycsb = ycsb[,-1]
  colnames(ycsb) = c("ts",
                     "throughput",
                     "max",
                     "min",
                     "avg",
                     "p90",
                     "p99",
                     "p999",
                     "p9999")

  ycsb =
    as_tibble(ycsb) %>%
    mutate(ts = sub("(\\d{2}):(\\d{3})", "\\1.\\2", ts)) %>%
    mutate_at(vars(ts), as.POSIXct) %>%
    mutate_at(vars(throughput, max, min, avg, p90, p99, p999, p9999),
              as.numeric)
}

load_checkpoint_marks = function(server_log_path, start_ts, end_ts, version) {
  if (version == 0) {
    checkpoint_start = "Starting replica checkpoint serialization"
    checkpoint_stop = "Next command occurred after \\d+s since last checkpoint"
  } else {
    checkpoint_start = "Starting replica checkpoint"
    checkpoint_stop = "Checkpoint created after \\d+s"
  }

  checkpoint_lines = regex(
    paste0(
      "(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}.\\d{3}).*",
      "(",
      checkpoint_start,
      "|",
      checkpoint_stop,
      ")"
    )
  )

  checkpoints = str_match(readLines(server_log_path), checkpoint_lines)
  checkpoints = checkpoints[!is.na(checkpoints[,1]),-1]
  colnames(checkpoints) = c("ts", "event")

  as_tibble(checkpoints) %>%
    mutate(event = sub(checkpoint_start, "Checkpoint Start", event)) %>%
    mutate(event = sub(checkpoint_stop, "Checkpoint Stop", event)) %>%
    mutate_at(vars(ts), as.POSIXct) %>%
    mutate_at(vars(event), as.factor) %>%
    filter(ts >= start_ts & ts <= end_ts)
}

load_gc_marks = function(gc_log_path, start_ts, end_ts) {
  gc_lines = regex("\\[(.*)\\+\\d+\\] GC\\(\\d+\\) (.*) \\d+\\w.*->\\d+\\w.*")
  
  pauses = str_match(readLines(gc_log_path), gc_lines)
  pauses = pauses[!is.na(pauses[, 1]), -1]
  colnames(pauses) = c("ts", "type")
  
  as_tibble(pauses) %>%
    mutate(ts = str_replace(ts, "T", " "),
           type = paste("GC", type)) %>%
    mutate_at(vars(ts), as.POSIXct) %>%
    mutate_at(vars(type), as.factor) %>%
    filter(ts >= start_ts & ts <= end_ts)
}

plot_througput_vs_checkpoints = function(title,
                                         ycsb_log,
                                         server_log,
                                         gc_log = NA,
                                         version = 1) {
  ycsb = load_ycsb_througput(ycsb_log)
  start = head(ycsb$ts)
  end = last(ycsb$ts)
  
  checkpoints = load_checkpoint_marks(server_log, start, end, version)
  
  plot = ggplot() +
    geom_line(data = ycsb, aes(ts, throughput)) +
    geom_vline(data = checkpoints,
               aes(xintercept = ts, color = event),
               linetype = "dashed") +
    labs(title = title,
         x = "Time",
         y = "Througput (requests/second)") +
    scale_color_discrete(name = "Markers:") +
    scale_y_continuous(breaks = pretty_breaks(15)) +
    theme(legend.position = "bottom")
  
  if (!is.na(gc_log)) {
    gc_pauses = load_gc_marks(gc_log, start, end)
    plot = plot +
      geom_vline(data = gc_pauses,
                 aes(xintercept = ts, color = type),
                 linetype = "dotted")
  }
  
  plot
}

plot_througput_vs_checkpoints(
  "Trie - G1",
  "../results/20201112T101439/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201112T101439/server/tmp/SmartTrie/logs/app.log",
  "../results/20201112T101439/server/tmp/SmartTrie/logs/gc.log"
)
```

# Experimentos

## 2020-10-09 - Baseline

Criação da baseline com aplicação tradicional. Configurações relevantes:

| Configuração | Valor | Observação |
|---|---|---|
| Servidores vs Clientes | 1/1 | Node 91-92 |
| Escrita vs Leitura | 100/0 | |
| Chaves | 500000 | |
| Requests | 500000 | |
| Threads no cliente | 1 | |
| Bytes/Registro | 4kb | |
| Período de checkpoints | 100000 | |
| Checkpoints assíncrono | Não | |
| Log assíncrono | Sim |
| Estrutura de dados | java.util.TreeMap | |
| Commit | 26544ab | |

Após a carga de dados, o estado em memória atingiu 1967MB (1.92G). Checkpoints levaram entre 30-40 segundos. A vazão da baseline parece irregular nos períodos entre checkpoints, o que motivou a execução com outros tipos de garbage collector. Por padrão a JVM 11 utiliza o algoritmo G1, porém, ZGC aparenta ser o algoritmo mais estável para esta aplicação. Dois bugs foram encontrados: 1) ao tentar executar a aplicação com 1M de chaves, a carga de dados é completada mas, o benchmark tem timeouts em praticamente todas as requisições; 2) ao reiniciar o servidor mantendo os dados persistidos, praticamente todas as requisições resultam em timeout (similar ao problema 1).

```{r experiment-2020-10-09-baseline, echo=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Baseline",
  "../results/20201009T132837/node92/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201009T132837/node91/tmp/SmartTrie/logs/app.log",
  version=0
)
```

```{r experiment-2020-10-09-parallel-gc, echo=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Baseline + ParallelGC",
  "../results/20201009T140936/node92/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201009T140936/node91/tmp/SmartTrie/logs/app.log",
  version=0
)
```

```{r experiment-2020-10-09-parallel-zgc, echo=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Baseline + ZGC",
  "../results/20201009T143012/node92/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201009T143012/node91/tmp/SmartTrie/logs/app.log",
  version=0
)
```

## 2020-10-17 - Reescrita dos Mecanismos de Checkpoint e Log

Nesta iteração, assumimos controle dos mecanismos de checkpoint e log. Para avaliar o impacto de tais componentes, reexecutamos a baseline. A seguir estão as configuração relevantes:

| Configuração | Valor | Observação |
|---|---|---|
| Servidores vs Clientes | 1/1 | Node 91-92 |
| Escrita vs Leitura | 100/0 | |
| Chaves | 500000 | |
| Requests | 500000 | |
| Threads no cliente | 1 | |
| Bytes/Registro | 4kb | |
| Período de Checkpoints | 100000 | |
| Checkpoints assíncrono | Sim/Não | TrieMap é assíncrono, demais são síncronos |
| Log assíncrono | Sim |
| Estrutura de dados | java.util.TreeMap, java.util.concurrent.HashMap, scala.collection.concurrent.TrieMap | |
| Commit | 3d47d90 | |

Iniciamos com a reexecução da baseline, utilizando uma estrutura de dados do tipo Tree-Map, e o algoritmo de GC paralelo. É visível que o tempo de execução do checkpoint diminuiu se comparado com a versão anterior do dia 09, que utiliza os algoritmos do BFT-Smart. No entanto, o comportamento é o mesmo: durante a execução do checkpoint nenhum comando é executado.

```{r experiment-2020-10-17-tree-map, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Baseline",
  "../results/20201017T144634/node92/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201017T144634/node91/tmp/SmartTrie/logs/app.log"
)
```

A título de curiosidade, reexecutamos também a baseline com o algoritmo de ZGC de garbage collector. O resultado foi semelhante ao obtido anteriormente: maior estabilidade apensar de menor vazão. A escolha do algoritmo correto de GC ainda não é clara. Os demais experimentos foram executados com o algoritmo paralelo de GC.

```{r experiment-2020-10-17-tree-map-zgc, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Baseline + ZGC",
  "../results/20201017T142212/node92/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201017T142212/node91/tmp/SmartTrie/logs/app.log"
)
```

A seguir, executamos um experimento similar, apenas variando o tipo da estrutura de um TreeMap (não thread-safe) para um ConcurrentHashMap (thread-safe). A hipótese é que a vazão de uma estrutura não thread-safe pode ser maior que a de uma estrutura thread-safe e, portanto, não seria uma comparação justa com a estrutura thread-safe CTrie. Ambas estruturas variam na mesma faixa de ~1800 a ~2200 RPS, sendo que a TreeMap se mantém mais próximo ao limite superior. Apesar disto, a instabilidade na vazão do serviço em ambos os casos torna difícil chegar a qualquer conclusão.

```{r experiment-2020-10-17-hash-map-parallel-gc, echo=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "ConcurrentHashMap",
  "../results/20201017T151954/node92/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201017T151954/node91/tmp/SmartTrie/logs/app.log"
)
```

Finalmente, executamos o mesmo experimento com uma estrutura do tipo CTrie, ou TrieMap em scala. Apesar da vazão ainda instável, é possível notar que não há a interrupção total do serviço durante o checkpoint. É interessante observar que ao final dos checkpoints, geralmente ocorre uma grande queda na vazão. Acreditamos que a queda esteja relacionada a uma rotina sincronizada que "trunca" os logs ao final do checkpoint.

```{r experiment-2020-10-17-trie-map-parallel-gc, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie",
  "../results/20201017T153644/node92/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201017T153644/node91/tmp/SmartTrie/logs/app.log"
)
```

O experimento com a CTrie se mostra promissor. No entanto, a instabilidade na vazão do serviço dificulta a sua análise. Próximos passos:

* Depurar o código afim de estabilizar a vazão do serviço;
* Reexecutar os experimentos.

<!-- Coleta de dados para depuração: ../results/20201017T121311 -->

## 2020-10-23 - Otimizações de memória e carga de dados

| Configuração | Valor | Observação |
|---|---|---|
| Servidores vs Clientes | 1/1 | Node 41-42 |
| Escrita vs Leitura | 100/0 | |
| Chaves | 500000 | |
| Requests | 5000000 | |
| Threads no cliente | 32 | |
| Bytes/Registro | 4kb | |
| Período de Checkpoints | 100000 | |
| Checkpoints assíncrono | Sim/Não | TrieMap é assíncrono, demais são síncronos |
| Log assíncrono | Sim |
| Estrutura de dados | java.util.TreeMap, java.util.concurrent.HashMap, scala.collection.concurrent.TrieMap | |
| Commit | c4cafdc | |

Neste experimento buscamos avaliar as otimizações feitas para reduzir as pausas de GC durante a execução dos sistema. Além disso, verificamos que os servidores 91 e 92 possuem um número grande de processos parallelos a execução do experimento (aproximadamente 700). Utilizamos, então, os servidores 41 e 42 que possuem memos processos em execução (~130). Aumentamos também o número de theads do benchmark afim de evitar períodos de lock no servidor devido a falta de trabalho a ser executado.

```{r experiment-2020-10-23-tree-map, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Baseline",
  "../results/20201023T095733/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201023T095733/server/tmp/SmartTrie/logs/app.log"
)
```

```{r experiment-2020-10-23-hash-map, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "ConcurrentHashMap",
  "../results/20201023T102244/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201023T102244/server/tmp/SmartTrie/logs/app.log"
)
```

```{r experiment-2020-10-23-trie-map, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie",
  "../results/20201023T104449/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201023T104449/server/tmp/SmartTrie/logs/app.log"
)
```

Apesar do aumento na vazão, a tempo de serviço continua instável. A variação aumentou em realção aos experimentos ateriores, o que dificulta ainda mais as análises.

## 2020-11-05 - Experimentos sem checkpoint e sem log

| Configuração | Valor | Observação |
|---|---|---|
| Servidores vs Clientes | 1/1 | Node 41-42 |
| Escrita vs Leitura | 100/0 | |
| Chaves | 500000 | |
| Requests | 500000 | |
| Threads no cliente | 1 | |
| Bytes/Registro | 4kb | |
| Período de Checkpoints | 100000 | |
| Checkpoints assíncrono | Sim | |
| Log assíncrono | Sim |
| Estrutura de dados | scala.collection.concurrent.TrieMap | |
| Commit | 686eb73 | Alterações foram feitas no código de maneira experimental (não há commits para cada experimento). |

Para avaliar o impacto dos mecanismos de checkpoint e log na vazão e aparente instabilidade do serviço. Os seguintes experimentos foram executados removendo as rotinas de log e checkpoint.

```{r experiment-2020-11-05-trie-no-ckp-no-log, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie - Sem Checkpoint - Sem Log",
  "../results/20201105T091931/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201105T091931/server/tmp/SmartTrie/logs/app.log"
)
```

```{r experiment-2020-11-05-trie-ckp-no-log, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie - Com Checkpoint - Sem Log",
  "../results/20201105T093940/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201105T093940/server/tmp/SmartTrie/logs/app.log"
)
```

```{r experiment-2020-11-05-trie-no-ckp-log, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie - Sem Checkpoint - Com Log",
  "../results/20201105T095706/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201105T095706/server/tmp/SmartTrie/logs/app.log"
)
```

É interessante perceber que mesmo sem checkpoints e logs, ainda ocorreu um período em que a vazão caiu a zero. O mesmo período não se repetiu nos experimentos seguintes, o que pode indicar que este seja um fator do ambiente, como pausas para GC ou perca de prioridade do SO. No entando, períodos de menor vazão parecem coinsidir com o término de checkpoints. Uma hipótese seria que o snapshot da CTrie criada em memória durante o checkpoint é descartado neste momento, liberando um espaço de memória significativo, o que pode disparar uma pausa de GC. Acredito que podemos remover o log a fim de reduzir as variáveis que podem impactar a vazão. Seria interessnate executar experimentos maiores, coletando uma média de vazão por alguns segundos, reduzindo assim a variação e focando as análises no seu valor médio ao longo do tempo.

## 2020-11-12 - Análize do impacto dos coletores de lixo

| Configuração | Valor | Observação |
|---|---|---|
| Servidores vs Clientes | 1/1 | Node 41-42 |
| Escrita vs Leitura | 100/0 | |
| Chaves | 500000 | |
| Requests | 5000000 | |
| Threads no cliente | 64 | |
| Bytes/Registro | 4kb | |
| Período de Checkpoints | 100000 | |
| Checkpoints assíncrono | Sim | |
| Log assíncrono | Sim |
| Estrutura de dados | scala.collection.concurrent.TrieMap | |
| Commit | 20110f9 | |

Neste experimento, removemos a rotina de log a fim de minimizar o número de variáveis que possam alterar a vazão. Comparamos em detalhe a execução do sistema com diferentes algoritmos de coleção. O primeiro experimento foi executado com o algoritmo ParallelGC, onde é possível observar quedas expressivas na vasão do serviço. Ao cruzar a vazão com as pausas de GC, é possível perceber que grandes quedas estão relacionadas a pausas longas do tipo "GC Pause Full".

```{r experiment-2020-11-12-trie-parallel-gc, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie - ParallelGC",
  "../results/20201112T094313/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201112T094313/server/tmp/SmartTrie/logs/app.log",
  "../results/20201112T094313/server/tmp/SmartTrie/logs/gc.log"
) + guides(colour = guide_legend(nrow = 2))
```

No experimento seguinte, avaliamos o desempenho ao escolher o algoritmo G1. É possível notar que este algoritmo passa por ciclos compostos de pequenas pausas que se tornam cada vez mais frequetes até um determinado limite onde pausas mais expressivas de GC são executadas o que resulta em períodos de menor vazão, ao contrário dos picos de baixa vazão encontrados no algoritmo ParallelGC.

```{r experiment-2020-11-12-trie-g1-gc, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie - G1",
  "../results/20201112T101439/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201112T101439/server/tmp/SmartTrie/logs/app.log",
  "../results/20201112T101439/server/tmp/SmartTrie/logs/gc.log"
) + guides(colour = guide_legend(nrow = 4))
```

Finalmente, re-executamos o mesmo experimento com o algoritmo ZGC. Este algoritmo apresenta pausas frequentes, o que resulta em uma maior desvio padrão, porém não há momentos de queda expressiva na vazão se comparado com os algoritmos anteriores.

```{r experiment-2020-11-12-trie-zgc, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie - ZGC",
  "../results/20201112T114719/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201112T114719/server/tmp/SmartTrie/logs/app.log",
  "../results/20201112T114719/server/tmp/SmartTrie/logs/gc.log"
)
```

Ao aumentar o tamanho máximo da memória de 6G para 8G, o ZGC preserva o desvio padrão, mas aumenta o periodo entre GCs.

```{r experiment-2020-11-13-trie-zgc-8G, echo=FALSE, message=FALSE, warning=FALSE}
plot_througput_vs_checkpoints(
  "Trie - ZGC",
  "../results/20201113T090532/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201113T090532/server/tmp/SmartTrie/logs/app.log",
  "../results/20201113T090532/server/tmp/SmartTrie/logs/gc.log"
)
```

Java flight recorder aponta para arrays de bytes como maior fonte de alocação. BFT-Smart, ao adotar arrays de bytes como estrutura base para representação de dados acaba por colocar muita pressão nos coletores de lixo uma vez que esta estrutura não pode ser reutilizada. A re-engenharia do BFT para utilizaar byte buffers reutilizáveis (pooled) pode amenizar este problema.

```{r experiment-2020-11-13-trie-zgc-8G-jfr, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Coleta de JFR em: ../results/20201113T092804/server/tmp/SmartTrie/recording.jfr
plot_througput_vs_checkpoints(
  "Trie - ZGC 8G",
  "../results/20201113T092804/client/tmp/SmartTrie/logs/benchmark.log",
  "../results/20201113T092804/server/tmp/SmartTrie/logs/app.log",
  "../results/20201113T092804/server/tmp/SmartTrie/logs/gc.log"
)
```

![](./img/Screen Shot 2020-11-13 at 10.02.40 AM.png)